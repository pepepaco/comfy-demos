{
  "1": {
    "inputs": {
      "ckpt_name": "Qwen-Rapid-AIO-NSFW-v23.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint"
    }
  },
  "2": {
    "inputs": {
      "seed": 798077143424620,
      "steps": 4,
      "cfg": 1,
      "sampler_name": "euler_ancestral",
      "scheduler": "beta",
      "denoise": 1,
      "model": [
        "1",
        0
      ],
      "positive": [
        "3",
        0
      ],
      "negative": [
        "15",
        0
      ],
      "latent_image": [
        "13",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "3": {
    "inputs": {
      "prompt": [
        "17",
        0
      ],
      "clip": [
        "1",
        1
      ],
      "vae": [
        "1",
        2
      ],
      "image1": [
        "14",
        0
      ]
    },
    "class_type": "TextEncodeQwenImageEditPlus",
    "_meta": {
      "title": "TextEncodeQwenImageEditPlus Input Prompt"
    }
  },
  "4": {
    "inputs": {
      "prompt": "",
      "clip": [
        "1",
        1
      ],
      "vae": [
        "1",
        2
      ]
    },
    "class_type": "TextEncodeQwenImageEditPlus",
    "_meta": {
      "title": "TextEncodeQwenImageEditPlus Negative (leave blank)"
    }
  },
  "5": {
    "inputs": {
      "samples": [
        "2",
        0
      ],
      "vae": [
        "1",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "7": {
    "inputs": {
      "image": "WhatsApp Image 2026-01-18 at 9.48.14 PM.jpeg"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Optional Input Image"
    }
  },
  "13": {
    "inputs": {
      "pixels": [
        "14",
        0
      ],
      "vae": [
        "1",
        2
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Encode"
    }
  },
  "14": {
    "inputs": {
      "upscale_method": "lanczos",
      "megapixels": 1.5,
      "resolution_steps": 3,
      "image": [
        "7",
        0
      ]
    },
    "class_type": "ImageScaleToTotalPixels",
    "_meta": {
      "title": "ImageScaleToTotalPixels"
    }
  },
  "15": {
    "inputs": {
      "conditioning": [
        "4",
        0
      ]
    },
    "class_type": "ConditioningZeroOut",
    "_meta": {
      "title": "ConditioningZeroOut"
    }
  },
  "16": {
    "inputs": {
      "filename_prefix": "chat",
      "images": [
        "5",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image for Chat"
    }
  },
  "17": {
    "inputs": {
      "prompt": "",
      "system_prompt": "# ROLE\r\nYou are a Senior Prompt Engineer specialized in Image Editing for models like Qwen Image Edit and Flux Kontext. Your goal is to transform a user's edit request and an input image into a precise, high-fidelity technical prompt that ensures seamless integration.\r\n\r\n# CORE OPERATIONAL RULES\r\n1. **ANALYZE FIRST**: Identify the subject's identity, lighting direction, material textures, and the overall artistic style (e.g., cinematic, 3D render, oil painting).\r\n2. **ANCHORING**: Explicitly name the elements that MUST remain identical (e.g., \"keeping the background, pose, and facial features unchanged\").\r\n3. **PHYSICAL INTEGRATION**: When adding or changing objects, describe how they interact with the environment. Mention shadows, reflections, and how the new element sits or rests within the space.\r\n4. **MATERIAL CONSISTENCY**: Match the texture of the new element to the existing scene (e.g., if the scene is grainy film, the edit must have film grain).\r\n5. **SPATIAL LOGIC**: Use precise positioning (e.g., \"placed directly behind,\" \"resting on the left edge of\") to avoid floating or misaligned objects.\r\n\r\n# PROMPT GUIDELINES\r\n- **Style Continuity**: Always reaffirm the original medium\/style at the end of the prompt to prevent \"style drift.\"\r\n- **Natural Narrative**: Write in fluid, descriptive English sentences. Avoid keyword stuffing or comma-separated lists.\r\n- **Negative Avoidance**: Describe what the new state looks like rather than telling the model what to \"remove.\"\r\n- **No Fluff**: Do not use \"masterpiece,\" \"8k,\" or \"ultra-detailed\" unless the user specifically asks for a quality boost.\r\n\r\n# OUTPUT STRUCTURE\r\nGenerate a single paragraph (50-120 words) following this flow:\r\n[Subject\/Context Preservation] + [Specific Modification with Physical & Lighting Details] + [Spatial Placement] + [Style\/Camera Anchor].\r\n\r\n# EXAMPLE\r\nUser Request: \"Add a black leather jacket to the man\"\r\nImproved Output: \"The man from the original image maintains his exact pose and facial expression, but is now wearing a premium black leather jacket with a subtle matte finish. The jacket features realistic creases and highlights that match the existing side-lighting of the scene. The original urban alleyway background and the cinematic 35mm film photography style remain untouched, ensuring the jacket looks perfectly integrated into the environment.\"\r\n\r\n# FINAL INSTRUCTION\r\nOutput ONLY the final prompt text. No explanations, no greetings, no markdown blocks.",
      "openai_url": "http://localhost:8080/v1/chat/completions",
      "api_key": "lm-studio",
      "model": "noctrex/Huihui-Qwen3-VL-4B-Instruct-abliterated-GGUF:Q8_0",
      "resize_percent": 30,
      "custom_properties": "{\"temperature\": 0.3}",
      "seed": 0,
      "bypass": "false",
      "image": [
        "7",
        0
      ]
    },
    "class_type": "OpenAICompat",
    "_meta": {
      "title": "OpenAICompat"
    }
  },
  "18": {
    "inputs": {
      "preview": "",
      "previewMode": false,
      "source": [
        "17",
        0
      ]
    },
    "class_type": "PreviewAny",
    "_meta": {
      "title": "Preview as Text"
    }
  }
}